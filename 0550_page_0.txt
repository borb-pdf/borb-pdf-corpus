                                                        YOLOv3: AnIncrementalImprovement
                                                                          Joseph Redmon, Ali Farhadi
                                                                                University of Washington
                                               Abstract                                                38                                                       YOLOv3
                                                                                                                                                                RetinaNet-50
                                                                                                       36                                     G                 RetinaNet-101
                    We present some updates to YOLO! We made a bunch                                                                              Method            mAP time
                 of little design changes to make it better. We also trained                                                                      [B] SSD321         28.0   61
                                                                                                       34                                         [C] DSSD321        28.0   85
                 this new network that’s pretty swell. It’s a little bigger than                                                          F       [D] R-FCN          29.9   85
                                                                                                                                                  [E] SSD513         31.2  125
                 last time but more accurate. It’s still fast though, don’t                            32                                         [F] DSSD513        33.2  156
                 worry. At 320 × 320 YOLOv3 runs in 22 ms at 28.2 mAP,                                                          E                 [G] FPN FRCN       36.2  172
                                                                                                      COCO AP                                     RetinaNet-50-500   32.5   73
                 as accurate as SSD but three times faster. When we look                               30           D                             RetinaNet-101-500  34.4   90
                                                                                                                                                  RetinaNet-101-800  37.8  198
                 at the old .5 IOU mAP detection metric YOLOv3 is quite                                                                           YOLOv3-320         28.2   22
                 good. It achieves 57.9 AP             in 51 ms on a Titan X, com-                     28    B      C                             YOLOv3-416         31.0   29
                                                   50                                                                                             YOLOv3-608         33.0   51
                 pared to 57.5 AP50 in 198 ms by RetinaNet, similar perfor-                              50             100            150            200            250
                 mance but 3.8× faster. As always, all the code is online at                                                      inference time (ms)
                 https://pjreddie.com/yolo/.                                                        Figure 1. We adapt this ﬁgure from the Focal Loss paper [9].
                                                                                                    YOLOv3 runs signiﬁcantly faster than other detection methods
                                                                                                    with comparable performance. Times from either an M40 or Titan
                 1. Introduction                                                                    X, they are basically the same GPU.
                    Sometimes you just kinda phone it in for a year, you                            2.1. Bounding Box Prediction
                 know? I didn’t do a whole lot of research this year. Spent                             Following YOLO9000 our system predicts bounding
                 a lot of time on Twitter. Played around with GANs a little.                        boxes using dimension clusters as anchor boxes [15]. The
                 I had a little momentum left over from last year [12] [1]; I                       network predicts 4 coordinates for each bounding box, tx,
                 managed to make some improvements to YOLO. But, hon-                               ty, tw, th. If the cell is offset from the top left corner of the
                 estly, nothing like super interesting, just a bunch of small                       imageby(c ,c )andtheboundingboxpriorhaswidthand
                 changes that make it better. I also helped out with other                                         x   y
                                                                                                    height p , p , then the predictions correspond to:
                 people’s research a little.                                                                  w h
                    Actually, that’s what brings us here today.                  We have
                 a camera-ready deadline [4] and we need to cite some of                                                       bx = σ(tx)+cx
                 the random updates I made to YOLO but we don’t have a                                                          by = σ(ty)+cy
                 source. So get ready for a TECH REPORT!                                                                                    t
                                                                                                                               b   =p ew
                    Thegreat thing about tech reports is that they don’t need                                                   w       w
                                                                                                                                            t
                                                                                                                               b =p eh
                 intros, y’all know why we’re here. So the end of this intro-                                                    h      h
                 ductionwillsignpostfortherestofthepaper. Firstwe’lltell
                 youwhatthedealiswithYOLOv3. Thenwe’lltellyouhow
                 we do. We’ll also tell you about some things we tried that                             During training we use sum of squared error loss. If the
                                                                                                                                                                  ˆ
                 didn’t work. Finally we’ll contemplate what this all means.                        ground truth for some coordinate prediction is t                 our gra-
                                                                                                                                                                   *
                                                                                                    dient is the ground truth value (computed from the ground
                                                                                                                                              ˆ
                                                                                                    truth box) minus our prediction: t − t . This ground truth
                 2. The Deal                                                                                                                   *      *
                                                                                                    value can be easily computed by inverting the equations
                    So here’s the deal with YOLOv3: We mostly took good                             above.
                 ideas from other people. We also trained a new classiﬁer                               YOLOv3predictsanobjectnessscoreforeachbounding
                 network that’s better than the other ones. We’ll just take                         boxusinglogisticregression. Thisshouldbe1ifthebound-
                 you through the whole system from scratch so you can un-                           ing box prior overlaps a ground truth object by more than
                 derstand it all.                                                                   any other bounding box prior. If the bounding box prior
                                                                                               1
